{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Lite is a branch of Tensorflow and aims the inference on the edge or resource-limited devices. In this topic, we start from a SavedModel trained on Tensorflow 2.x and then convert it to a Tensorflow Lite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-08 17:07:36,422-INFO:Tensorflow Version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as lite\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s-%(levelname)s:%(message)s\")\n",
    "logging.info(\"Tensorflow Version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model\n",
    "\n",
    "Here we prepare a Tensorflow model in `SavedModel` format. The model is trained on the MNIST dataset. The source code can refer to the [link](https://github.com/jiankaiwang/aiot/blob/master/tensorrt/trainingMNIST.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistPath = \"/Users/jiankaiwang/Desktop/mnist\"\n",
    "assert os.path.exists(mnistPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_2'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28, 1)\n",
      "        name: serving_default_input_2:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_5'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /Users/jiankaiwang/devops/pyenv/tf2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_2')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_2')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_2')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_2')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_2: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='input_2')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir {mnistPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion\n",
    "\n",
    "The following is a quick start for converting a SavedModel to tflite. You can convert a model in SavedModel format to a Tensorflow Lite model via a built-in tool `tflite_convert`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tflite_convert [-h] --output_file OUTPUT_FILE\n",
      "                      [--saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE]\n",
      "                      [--enable_v1_converter]\n",
      "                      [--experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]]\n",
      "\n",
      "Command line tool to run TensorFlow Lite Converter.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --output_file OUTPUT_FILE\n",
      "                        Full filepath of the output file.\n",
      "  --saved_model_dir SAVED_MODEL_DIR\n",
      "                        Full path of the directory containing the SavedModel.\n",
      "  --keras_model_file KERAS_MODEL_FILE\n",
      "                        Full filepath of HDF5 file containing tf.Keras model.\n",
      "  --enable_v1_converter\n",
      "                        Enables the TensorFlow V1 converter in 2.0\n",
      "  --experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]\n",
      "                        Experimental flag, subject to change. Enables MLIR-\n",
      "                        based conversion instead of TOCO conversion.\n"
     ]
    }
   ],
   "source": [
    "!tflite_convert -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-08 17:05:12.332916: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-10-08 17:05:12.372935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e9036adc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-08 17:05:12.372960: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-08 17:05:12.678846: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n",
      "2020-10-08 17:05:12.678948: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2020-10-08 17:05:12.682887: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
      "2020-10-08 17:05:12.682905: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 43 nodes (34), 61 edges (52), time = 2.065ms.\n",
      "2020-10-08 17:05:12.682910: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.07ms.\n",
      "2020-10-08 17:05:12.751768: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n",
      "2020-10-08 17:05:12.751908: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2020-10-08 17:05:12.778556: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\n",
      "2020-10-08 17:05:12.778581: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 37 nodes (-6), 49 edges (-12), time = 16.928ms.\n",
      "2020-10-08 17:05:12.778586: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 37 nodes (0), 49 edges (0), time = 2.955ms.\n",
      "I1008 17:05:12.788880 4451372480 lite.py:509] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    }
   ],
   "source": [
    "outputPath = \"/Users/jiankaiwang/Desktop/mnist_tflite/mnist_savedmodel.tflite\"\n",
    "!tflite_convert --saved_model_dir={mnistPath} --output_file={outputPath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "\n",
    "You can further convert the model in an advanced way. e.g. `quantization`, etc. Such a convert can be done through the Tensorflow built-in APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-08 17:05:16,189-INFO:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n"
     ]
    }
   ],
   "source": [
    "converter = lite.TFLiteConverter.from_saved_model(mnistPath)\n",
    "converter.optimizations = [lite.Optimize.DEFAULT]\n",
    "tfliteQuantModel = converter.convert()\n",
    "\n",
    "outputQuantPath = \"/Users/jiankaiwang/Desktop/mnist_tflite/mnist_savedmodel_quant.tflite\"\n",
    "with open(outputQuantPath, \"wb\") as fout:\n",
    "  fout.write(tfliteQuantModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(imgPath):\n",
    "  \"\"\"Normalize the image to the scale in [-1, 1].\"\"\"\n",
    "  _img = tf.io.read_file(imgPath)\n",
    "  _img = tf.image.decode_jpeg(_img)\n",
    "  img = tf.cast(_img, tf.float32)\n",
    "  img = (img - 127.5) / 127.5\n",
    "  return img, _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImgpath = \"/Users/jiankaiwang/Desktop/mnist_four.jpg\"\n",
    "img, _img = normalize(testImgpath)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAHVUlEQVR4nO3dS4hedxnH8XPeuaRNW2tFJdg2iWnNRKogFG21CvWGgmJFcFNcFrFFqZeFoIssdOPCRRFaBF1YL4uKbhREVGyoxEULjUKNKMo0JFSnLUhtk8lcznE9MOc5OjOv85vJ57Psw8k7ofnmD3n4n7ft+74B8kx2+wcANidOCCVOCCVOCCVOCDVbDT84+aR/yoUp+1X343az/+7khFDihFDihFDihFDihFDihFDihFDihFDihFDihFDihFDihFDihFDihFDihFDlfU6uQJOZ4Vm3PtWPbmeH/zj2a2tT/exETk4IJU4IJU4IJU4IJU4IJU4IZZXCBu1k07c0Nk3TNH033c+u1iXtgQP1s5cv7/SPs+ucnBBKnBBKnBBKnBBKnBBKnBBKnBDKnpMN2vn5wVnf1d8I2c4U182apulXV+rn54rP3od7zDFOTgglTgglTgglTgglTgglTgglTghlz8lG3fClzaX77ygfffqrD5fztzz0QDm/8Runy3mpHb6H2jRN0/T1jjaRkxNCiRNCiRNCiRNCiRNCiRNCiRNC2XOyQV/sA1//iXPb+rVXbhjZNRa7yuqeadPsz/ueTk4IJU4IJU4IJU4IJU4IJU4IZZXCRm990+DoJwvfKR/9yj/fUc5v/d4L5Xy9HT4rRlclk/q1nE23Xs8DOTkhlDghlDghlDghlDghlDghlDghlD0nG/z1wbnB2bWTq8pnTz9/rJxf/eyFct7ODf9x7C+P7Cn34B5zjJMTQokTQokTQokTQokTQokTQokTQtlzbsGle+p7i3ecfLKcn/nC2wZnk1NPb+VH2jG3v3Hrr788d/ZQOT++/lw534+vt9wOJyeEEieEEieEEieEEieEEieEEieEsufcRHvgQDmfvdSV8y++9olyfvcH7hycHT1VPtq0cyNfhbe6Us5nj9xczh879rPB2fm1l8tnF777r3Lera6V83a2uM+5Vj+7Hzk5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ95xZcdeHf5fw1M/WetGmLUbHra5rxPebY91Qu3lvvOdf74R3ut158d/lsf/bv5XwyP/xO3KZpmm55uZxfaZycEEqcEEqcEEqcEEqcEEqcEMoqZQsu3fyqcr7a119H11Y3zmbqVchkvr4y1i3Xr5e8eKS+ejXTDv99/dhTby+fXejr13p2K/vva/qmyckJocQJocQJocQJocQJocQJocQJoew5N9P15fjZj9R/px1o66tRfbXKHPnspl6DNjMnbinnP//wQ+V8vR++7rbw8MX6w8d0I3vO6rrb2LP7kJMTQokTQokTQokTQokTQokTQokTQtlzbmJy/XXl/PF7vlnO59pry/n9H//F4Ozbx99TPnvo1S+V8/sO/6ac3zZ/dTn/+gsnBmft2b+Vz3ZjO9q2eCdo01yRu8yKkxNCiRNCiRNCiRNCiRNCiRNCiRNC2XNuYvEzC+X88Gy9xxzz+RsWh2d3Dc/+H376yHsHZ69b/n357OjXF3YjZ8HI+36vNE5OCCVOCCVOCCVOCCVOCCVOCCVOCGXPuYlLh1fL+V9WXynnH/r1g+V8bmn4vbYzy/Wdx2vO13cmn/raI+V8zKEfPjM468b2mGv1d3/uqrG7pP3IXdRd4OSEUOKEUOKEUOKEUOKEUOKEUFYpmzj+6SfL+eeau8r5wuyZct6vF1ejRv5Jf+mz7yrnY97/p4+V89mXLwwP9/KrKwNXJWOcnBBKnBBKnBBKnBBKnBBKnBBKnBDKnnMKRq9OjV1fKhz86D/K+XrflfPFP76hnN/anfuff6b/2h68trWbnJwQSpwQSpwQSpwQSpwQSpwQSpwQyp5zN2xjn/fomx8t5zNt/fWEN/223oNuiz3mjnJyQihxQihxQihxQihxQihxQihxQih7zmmYzNTz4v2va++7feQX/105/dTi3eX8mlN/LufbejOtPeaOcnJCKHFCKHFCKHFCKHFCKHFCKKuUaRh5PeXk4MHB2XUnz5fP3jJXXwn7wdHHy/mJLz1Qzo+cPF3Od80VeB3NyQmhxAmhxAmhxAmhxAmhxAmhxAmh7DmnYWTn1l28ODhb668vn11af6Wc/+il28r5se8/V863dWVsmvbhHnOMkxNCiRNCiRNCiRNCiRNCiRNCiRNC2XOGue/GJ8r58+v136e/vPed5bxdulD/ANW9yb28a9yD90GdnBBKnBBKnBBKnBBKnBBKnBBKnBDKnnMrprgzOzr7Yjk/c/mmct794Ww5b+fm6x8gcN+3I/bg78vJCaHECaHECaHECaHECaHECaHECaHsObdibGc2mann3fDbYb987M7tfTb7hpMTQokTQokTQokTQokTQokTQlmlTEOxKhk1sioZu/LVr65sa04OJyeEEieEEieEEieEEieEEieEEieEsufcim1cCduusT1lO1v/L+3X1nbyx2GKnJwQSpwQSpwQSpwQSpwQSpwQSpwQqu29ahEiOTkhlDghlDghlDghlDghlDgh1H8AiD5ELivG5JYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showImg(img):\n",
    "  plt.figure()\n",
    "  plt.imshow(img)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "\n",
    "showImg(_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n",
    "\n",
    "By default, you can load a `tflite` model via the Tensorflow built-in APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-08 17:05:19,686-WARNING:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 256)               533248    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Label [4] with Prob 99.923%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiankaiwang/devops/pyenv/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(mnistPath)\n",
    "model.summary()\n",
    "\n",
    "preds = model.predict(img)\n",
    "label = tf.argmax(preds, axis=1)\n",
    "pred = preds[0][label]\n",
    "print(\"Label {} with Prob {:.3f}%\".format(label, pred*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_details: [{'name': 'input_2', 'index': 0, 'shape': array([ 1, 28, 28,  1], dtype=int32), 'shape_signature': array([ 1, 28, 28,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] \n",
      "output_details: [{'name': 'Identity', 'index': 12, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] \n",
      "\n",
      "input_shape: [ 1 28 28  1]\n",
      "Label [4] with Prob 99.923%\n",
      "Time Cost: 0.0058858394622802734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiankaiwang/devops/pyenv/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "__start = time.time()\n",
    "\n",
    "# load the TFLite model and allocate tensors\n",
    "interpreter = lite.Interpreter(model_path=outputPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"input_details:\", input_details, \"\\noutput_details:\", output_details, \"\\n\")\n",
    "\n",
    "# infer the image\n",
    "input_shape = input_details[0]['shape']\n",
    "print(\"input_shape:\", input_shape)\n",
    "interpreter.set_tensor(input_details[0]['index'], img)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# get the result\n",
    "preds = interpreter.get_tensor(output_details[0]['index'])\n",
    "label = tf.argmax(preds, axis=1)\n",
    "pred = preds[0][label]\n",
    "print(\"Label {} with Prob {:.3f}%\".format(label, pred*100))\n",
    "\n",
    "print(\"Time Cost: {}\".format(time.time() - __start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFLite Runtime\n",
    "\n",
    "If you want to infer the data only without installing the whole Tensorflow package, you can install the tflite runtime only. You can select the suitable package to install tflite runtime from the [link](https://www.tensorflow.org/lite/guide/python). Here we use the one whose label are `macOS 10.14` and `Python 3.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp37-cp37m-macosx_10_14_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of installing the Tensorflow, you can install the tflite runtime only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_details: [{'name': 'input_2', 'index': 0, 'shape': array([ 1, 28, 28,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}] \n",
      "output_details: [{'name': 'Identity', 'index': 12, 'shape': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputPath = \"/Users/jiankaiwang/Desktop/mnist_tflite/mnist_savedmodel.tflite\"\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path=outputPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"input_details:\", input_details, \"\\noutput_details:\", output_details, \"\\n\")\n",
    "\n",
    "# infer the image\n",
    "# ... the same as the previos section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with a Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_details: [{'name': 'input_2', 'index': 0, 'shape': array([ 1, 28, 28,  1], dtype=int32), 'shape_signature': array([ 1, 28, 28,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] \n",
      "output_details: [{'name': 'Identity', 'index': 12, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([ 1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}] \n",
      "\n",
      "input_shape: [ 1 28 28  1]\n",
      "Label [4] with Prob 99.923%\n",
      "Time Cost: 0.007762908935546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiankaiwang/devops/pyenv/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "outputQuantPath = \"/Users/jiankaiwang/Desktop/mnist_tflite/mnist_savedmodel_quant.tflite\"\n",
    "\n",
    "__start = time.time()\n",
    "interpreter = lite.Interpreter(model_path=outputPath)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(\"input_details:\", input_details, \"\\noutput_details:\", output_details, \"\\n\")\n",
    "\n",
    "# infer the image\n",
    "input_shape = input_details[0]['shape']\n",
    "print(\"input_shape:\", input_shape)\n",
    "interpreter.set_tensor(input_details[0]['index'], img)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# get the result\n",
    "preds = interpreter.get_tensor(output_details[0]['index'])\n",
    "label = tf.argmax(preds, axis=1)\n",
    "pred = preds[0][label]\n",
    "print(\"Label {} with Prob {:.3f}%\".format(label, pred*100))\n",
    "print(\"Time Cost: {}\".format(time.time() - __start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
